{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yadu/miniconda3/envs/ian_pipeline/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsl backend init\n",
    "\n",
    "Here we load a barebones remote execution backend for parsl to form a decent baseline that includes all the costs of remote function instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7fa8a23ba908>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.configs.htex_local import config\n",
    "\n",
    "# Most of the app that hit the timeout will complete if retried.\n",
    "# but for this demo, I'm not setting retries.\n",
    "# config.retries = 2\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need this import here, but we should ideally be loading \n",
    "# all the apps from a separate module\n",
    "# import main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Smiles data\n",
    "Here we load only 158 lines from the csv file, to avoid burning the laptop. Once we replace the config\n",
    "with a config for theta, we can load and launch the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data available\n",
      "Total of 158 available\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading all data available\")\n",
    "smiles = pd.read_csv(\"train.csv\", nrows=158).iloc[:,0].tolist()\n",
    "print(\"Total of {} available\".format(len(smiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update descript to process batches\n",
    "\n",
    "We want the descript step to consume batches of smiles to minimize the task launch costs.\n",
    "Here we add a `@python_app` decorator that marks this function for remote/distributed execution.\n",
    "\n",
    "Key point to note is that we add a special `walltime=<int:seconds>` kwarg, that causes the function to raise a `parsl.app.errors.AppTimeout` exception if the function runs beyond the set walltime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def app_compute_descript_batches(smile_list, walltime=1):\n",
    "    \"\"\" Takes a list of smiles and returns a corresponding list of descs.\n",
    "    \"\"\"\n",
    "    from mordred import Calculator, descriptors\n",
    "    from rdkit import Chem\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    # this object doesn't need to be created everytime. Can make global I think?                                                                                                                                    \n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "\n",
    "    results_list = []\n",
    "    for smile in smile_list:\n",
    "        #read smiles                                                                                                                                                                                                    \n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol is None:\n",
    "            print(\"Error processing mol\")\n",
    "            result = None\n",
    "        else:\n",
    "            descs = calc(mol)\n",
    "            result = pickle.dumps(np.array(descs).flatten().astype(np.float32))\n",
    "            \n",
    "        results_list.append(result)\n",
    "\n",
    "    return results_list\n",
    "\n",
    "\n",
    "# This will change, but the interface will not.\n",
    "@python_app\n",
    "def combine_drug_features_with_cell_features(vec_list):\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    results = []\n",
    "    for b_vec in vec_list:\n",
    "        vec = pickle.loads(b_vec)\n",
    "        vec_prime = np.zeros((60, vec.shape[0]))\n",
    "        vec_prime[0] = vec\n",
    "\n",
    "        #will need to impute missing values                                                                                \n",
    "        imp = Imputer()\n",
    "        vec_prime = imp.fit_transform(vec_prime)\n",
    "        results.append(pickle.dumps(vec_prime)) # <-- Another serialization pain point\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch tasks on chunks of data\n",
    "\n",
    "Parsl does batching internally, but we can do better!\n",
    "\n",
    "We have an estimate of the runtime for a batch of N tasks, and we use that to our advantage by creating\n",
    "chunks of \"smiles\" that are dispatched to the now batched, `app_compute_descript_batches` function.\n",
    "\n",
    "`chunksize` is configurable. In a smarter version we could tie `chunksize` and `walltime` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_tasks(data, chunksize=10):\n",
    "    proc_chunks = {}\n",
    "    result_chunks = {}\n",
    "    for i in range(1, len(data), chunksize):    \n",
    "        chunk = data[i:i+chunksize]\n",
    "        descript_vecs_list = app_compute_descript_batches(chunk)\n",
    "        training_batch_list = combine_drug_features_with_cell_features(descript_vecs_list)\n",
    "        proc_chunks[i] = descript_vecs_list\n",
    "        result_chunks[i] = training_batch_list\n",
    "    return proc_chunks, result_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial launch of all tasks\n",
    "proc_chunks, result_chunks = launch_tasks(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture and report messages on failed chunks\n",
    "\n",
    "This is just a demonstration of how batches of smiles that exceed the runtime limits will simply raise a python exception when the \"future\" that represents the batch is asked to produce the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught timeout for chunk index: 71:81\n",
      "Caught timeout for chunk index: 111:121\n",
      "Caught timeout for chunk index: 131:141\n"
     ]
    }
   ],
   "source": [
    "# Wait for the results\n",
    "from parsl.app.errors import AppTimeout\n",
    "chunksize=10\n",
    "for key in proc_chunks:\n",
    "    try:\n",
    "        x = proc_chunks[key].result()\n",
    "    except AppTimeout as e:\n",
    "        print(\"Caught timeout for chunk index: {}:{}\".format(key,key+chunksize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: <AppFuture super=<AppFuture at 0x7fa89f3faa90 state=finished returned list>>, 11: <AppFuture super=<AppFuture at 0x7fa89cadaa58 state=finished returned list>>, 21: <AppFuture super=<AppFuture at 0x7fa89cada6a0 state=finished returned list>>, 31: <AppFuture super=<AppFuture at 0x7fa89cada710 state=finished returned list>>, 41: <AppFuture super=<AppFuture at 0x7fa89cadab70 state=finished returned list>>, 51: <AppFuture super=<AppFuture at 0x7fa89cadad30 state=finished returned list>>, 61: <AppFuture super=<AppFuture at 0x7fa89cadada0 state=finished returned list>>, 71: <AppFuture super=<AppFuture at 0x7fa89cadaa20 state=finished raised AppTimeout>>, 81: <AppFuture super=<AppFuture at 0x7fa89cb084a8 state=finished returned list>>, 91: <AppFuture super=<AppFuture at 0x7fa89cb084e0 state=finished returned list>>, 101: <AppFuture super=<AppFuture at 0x7fa89cb08cf8 state=finished returned list>>, 111: <AppFuture super=<AppFuture at 0x7fa89cb08208 state=finished raised AppTimeout>>, 121: <AppFuture super=<AppFuture at 0x7fa89cb08fd0 state=finished returned list>>, 131: <AppFuture super=<AppFuture at 0x7fa89ca93588 state=finished raised AppTimeout>>, 141: <AppFuture super=<AppFuture at 0x7fa89ca93e10 state=finished returned list>>, 151: <AppFuture super=<AppFuture at 0x7fa89ca93908 state=finished returned list>>}\n"
     ]
    }
   ],
   "source": [
    "print(proc_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle the failed batches\n",
    "\n",
    "For the failed batches, we call `launch_tasks` again, but in this instance we call it with a `chunksize=1` so that\n",
    "we can pinpoint which `smile` is non-convergent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching unpacked tasks: 71:81\n",
      "Launching unpacked tasks: 111:121\n",
      "Launching unpacked tasks: 131:141\n"
     ]
    }
   ],
   "source": [
    "unpacked = {}\n",
    "unpacked_tail = {}\n",
    "for key in proc_chunks:\n",
    "    try:\n",
    "        x = proc_chunks[key].result()\n",
    "    except AppTimeout as e:        \n",
    "        print(\"Launching unpacked tasks: {}:{}\".format(key,key+chunksize))\n",
    "        unpacked[key], unpacked_tail[key] = launch_tasks(smiles[key:key+chunksize], chunksize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display specific smile that failed to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peeking inside batch 71:81 ------------\n",
      "   Item 1\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca62cf8 state=pending>>\n",
      "   Item 2\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76c18 state=pending>>\n",
      "   Item 3\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca62f98 state=pending>>\n",
      "   Item 4\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76278 state=pending>>\n",
      "   Item 5\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca761d0 state=pending>>\n",
      "   Item 6\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80d68 state=pending>>\n",
      "   Item 7\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76908 state=pending>>\n",
      "   Item 8\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca800f0 state=pending>>\n",
      "   Item 9\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76e48 state=pending>>\n",
      "---------------------------------------\n",
      "Peeking inside batch 111:121 ------------\n",
      "   Item 1\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80908 state=pending>>\n",
      "   Item 2\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca8b940 state=pending>>\n",
      "   Item 3\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80748 state=pending>>\n",
      "   Item 4\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca8b748 state=pending>>\n",
      "   Item 5\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca805c0 state=pending>>\n",
      "   Item 6\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16e80 state=pending>>\n",
      "   Item 7\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80be0 state=pending>>\n",
      "   Item 8\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16390 state=pending>>\n",
      "   Item 9\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80198 state=pending>>\n",
      "---------------------------------------\n",
      "Peeking inside batch 131:141 ------------\n",
      "   Item 1\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16160 state=pending>>\n",
      "   Item 2\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca253c8 state=pending>>\n",
      "   Item 3\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16da0 state=pending>>\n",
      "   Item 4\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca25eb8 state=pending>>\n",
      "   Item 5\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16668 state=pending>>\n",
      "   Item 6\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca31f60 state=pending>>\n",
      "   Item 7\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16080 state=pending>>\n",
      "   Item 8\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca31da0 state=pending>>\n",
      "   Item 9\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16908 state=pending>>\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in unpacked:\n",
    "    print(\"Peeking inside batch {}:{} ------------\".format(key, key+chunksize))\n",
    "    for item in unpacked[key]:\n",
    "        print(\"   Item {}\".format(item))\n",
    "        print(unpacked[key][item])\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{71: {1: <AppFuture super=<AppFuture at 0x7fa89ca76c50 state=finished returned list>>, 2: <AppFuture super=<AppFuture at 0x7fa89ca62c50 state=finished returned list>>, 3: <AppFuture super=<AppFuture at 0x7fa89ca76048 state=finished returned list>>, 4: <AppFuture super=<AppFuture at 0x7fa89ca76860 state=finished returned list>>, 5: <AppFuture super=<AppFuture at 0x7fa89ca800b8 state=finished returned list>>, 6: <AppFuture super=<AppFuture at 0x7fa89ca76518 state=finished returned list>>, 7: <AppFuture super=<AppFuture at 0x7fa89ca806a0 state=finished returned list>>, 8: <AppFuture super=<AppFuture at 0x7fa89ca76080 state=finished returned list>>, 9: <AppFuture super=<AppFuture at 0x7fa89ca80080 state=finished returned list>>}, 111: {1: <AppFuture super=<AppFuture at 0x7fa89ca8b0f0 state=finished returned list>>, 2: <AppFuture super=<AppFuture at 0x7fa89ca80a90 state=finished returned list>>, 3: <AppFuture super=<AppFuture at 0x7fa89ca8b0b8 state=finished returned list>>, 4: <AppFuture super=<AppFuture at 0x7fa89ca80c88 state=finished returned list>>, 5: <AppFuture super=<AppFuture at 0x7fa89ca16d68 state=finished returned list>>, 6: <AppFuture super=<AppFuture at 0x7fa89ca80278 state=finished returned list>>, 7: <AppFuture super=<AppFuture at 0x7fa89ca16978 state=finished returned list>>, 8: <AppFuture super=<AppFuture at 0x7fa89ca80a58 state=finished returned list>>, 9: <AppFuture super=<AppFuture at 0x7fa89ca16c50 state=finished returned list>>}, 131: {1: <AppFuture super=<AppFuture at 0x7fa89ca25a20 state=finished returned list>>, 2: <AppFuture super=<AppFuture at 0x7fa89caacc18 state=finished returned list>>, 3: <AppFuture super=<AppFuture at 0x7fa89ca25ba8 state=finished returned list>>, 4: <AppFuture super=<AppFuture at 0x7fa89ca16320 state=finished raised DependencyError>>, 5: <AppFuture super=<AppFuture at 0x7fa89ca31e10 state=finished raised DependencyError>>, 6: <AppFuture super=<AppFuture at 0x7fa89ca169e8 state=finished returned list>>, 7: <AppFuture super=<AppFuture at 0x7fa89ca31668 state=finished returned list>>, 8: <AppFuture super=<AppFuture at 0x7fa89ca16b00 state=finished returned list>>, 9: <AppFuture super=<AppFuture at 0x7fa89ca31710 state=finished returned list>>}}\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76c50 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca62c50 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76048 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76860 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca800b8 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76518 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca806a0 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca76080 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80080 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca8b0f0 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80a90 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca8b0b8 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80c88 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16d68 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80278 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16978 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca80a58 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16c50 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca25a20 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89caacc18 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca25ba8 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16320 state=finished raised DependencyError>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca31e10 state=finished raised DependencyError>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca169e8 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca31668 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca16b00 state=finished returned list>>\n",
      "<AppFuture super=<AppFuture at 0x7fa89ca31710 state=finished returned list>>\n"
     ]
    }
   ],
   "source": [
    "print(unpacked_tail)\n",
    "for batch in unpacked_tail:\n",
    "    for item in unpacked_tail[batch]:\n",
    "        print(unpacked_tail[batch][item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = unpacked_tail[71][1].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.15871429  13.76257515   0.         ... 107.           8.66666698\n",
      "    4.97222233]\n",
      " [  0.           0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " ...\n",
      " [  0.           0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.         ...   0.           0.\n",
      "    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "r = pickle.loads(x[0])\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
